# üîç AN√ÅLISIS: ¬øEl Asistente IA lee TODO el contexto?

## ‚úÖ LO QUE S√ç EST√Å FUNCIONANDO

### 1. **El asistente IA S√ç lee todo el transcript acumulado**

**C√≥digo:** [server.py:285](c:\Trabajo\Clinica\Medberos\NewMed\consultia\backend\server.py#L285)
```python
asyncio.create_task(stream_summary(ws, state["final"]))
```

- ‚úÖ `state["final"]` contiene **TODO** el texto transcrito desde el inicio
- ‚úÖ Se acumula con cada mensaje `"final"` que llega
- ‚úÖ La IA ve TODO el contexto conversacional

**Ejemplo:**
```python
# Primera transcripci√≥n
state["final"] = "Paciente con fiebre."

# Segunda transcripci√≥n
state["final"] = "Paciente con fiebre. Tiene tos seca."

# La IA siempre recibe el texto completo acumulado
```

---

## ‚ùå LO QUE NO EST√Å FUNCIONANDO

### 1. **El asistente IA NO recibe informaci√≥n sobre campos faltantes**

**C√≥digo actual:** [server.py:100-129](c:\Trabajo\Clinica\Medberos\NewMed\consultia\backend\server.py#L100-L129)

```python
async def stream_summary(ws: WebSocket, transcript: str):
    system = (
        "Eres un asistente cl√≠nico. Resume en 2‚Äì4 l√≠neas lo m√°s relevante del caso: "
        "motivo de consulta, s√≠ntomas clave, hallazgos, y si falta informaci√≥n para la historia cl√≠nica. "
        "No inventes datos y mant√©n tono profesional."
    )

    stream = client.chat.completions.create(
        model=OPENAI_MODEL_TEXT,
        messages=[
            {"role": "system", "content": system},
            {"role": "user", "content": transcript}  # ‚ùå SOLO recibe transcript
        ],
        temperature=0.2,
        stream=True
    )
```

**Problema:**
- ‚ùå NO recibe `missing` (campos faltantes)
- ‚ùå NO recibe `suggestions` (sugerencias)
- ‚ùå NO recibe el estado actual del formulario

**Resultado:**
El asistente IA genera un resumen general, pero **NO menciona** qu√© campos faltan ni qu√© informaci√≥n se necesita.

---

### 2. **Las sugerencias se env√≠an al frontend pero NO a la IA**

**Flujo actual:**

```
Backend calcula ‚Üí missing = ["diagnosticos", "tratamientos"]
               ‚Üì
Backend genera ‚Üí suggestions = ["Registre al menos un diagn√≥stico..."]
               ‚Üì
Backend env√≠a al frontend ‚Üí {"type": "form_update", "suggestions": [...]}
               ‚Üì
Frontend muestra sugerencias en UI ‚úÖ
               ‚Üì
IA NO las ve ‚ùå
```

**Por qu√©:**
La funci√≥n `stream_summary()` se ejecuta **ANTES** de calcular `missing` y `suggestions`:

```python
# PASO 1: Se genera el resumen (NO tiene missing/suggestions a√∫n)
asyncio.create_task(stream_summary(ws, state["final"]))

# PASO 2: Se extrae el formulario y se calculan missing/suggestions
asyncio.create_task(run_incremental_update(...))
```

---

## üéØ C√ìMO VERIFICAR EL PROBLEMA

### Prueba 1: Di solo esto
```
"Paciente con fiebre"
```

**Resultado esperado actual:**
- ‚úÖ Asistente IA: "Paciente refiere fiebre. Se requiere m√°s informaci√≥n..."
- ‚úÖ Campos faltantes: ["Motivo de consulta", "S√≠ntomas principales", "diagn√≥sticos", "tratamientos"]
- ‚úÖ Sugerencias: Aparecen en la UI

**Problema:**
- ‚ùå El asistente IA NO dice expl√≠citamente "Falta registrar diagn√≥sticos y tratamientos"

### Prueba 2: Completa motivo y s√≠ntomas
```
"Paciente acude por fiebre. S√≠ntomas principales: fiebre, tos, dolor de garganta."
```

**Resultado esperado mejorado:**
- ‚úÖ Asistente IA deber√≠a decir: "Paciente con s√≠ntomas respiratorios. **Pendiente: diagn√≥sticos y plan de tratamiento.**"
- Pero actualmente NO lo hace ‚ùå

---

## üîß SOLUCIONES PROPUESTAS

### Opci√≥n 1: Modificar `stream_summary()` para recibir contexto adicional

**Cambio en [server.py:100](c:\Trabajo\Clinica\Medberos\NewMed\consultia\backend\server.py#L100):**

```python
async def stream_summary(
    ws: WebSocket,
    transcript: str,
    missing: List[str] = [],      # ‚Üê NUEVO
    suggestions: List[str] = []   # ‚Üê NUEVO
):
    # Construir contexto enriquecido
    context_parts = [transcript]

    if missing:
        missing_str = ", ".join(missing)
        context_parts.append(f"\n\nCAMPOS FALTANTES: {missing_str}")

    if suggestions:
        sugg_str = "\n".join(f"- {s}" for s in suggestions)
        context_parts.append(f"\n\nSUGERENCIAS PARA COMPLETAR:\n{sugg_str}")

    full_context = "\n".join(context_parts)

    system = (
        "Eres un asistente cl√≠nico. Resume en 2‚Äì4 l√≠neas lo m√°s relevante del caso. "
        "Si hay campos faltantes, menci√≥nalos brevemente al final. "
        "Mant√©n tono profesional y √∫til."
    )

    stream = client.chat.completions.create(
        model=OPENAI_MODEL_TEXT,
        messages=[
            {"role": "system", "content": system},
            {"role": "user", "content": full_context}  # ‚Üê Contexto enriquecido
        ],
        temperature=0.2,
        stream=True
    )
```

**Resultado esperado:**
```
Asistente IA: "Paciente con cuadro febril y s√≠ntomas respiratorios.
Presi√≥n arterial normal. Pendiente: registrar diagn√≥sticos y plan de tratamiento."
```

---

### Opci√≥n 2: Invocar `stream_summary()` DESPU√âS de calcular missing/suggestions

**Cambio en [server.py:283-302](c:\Trabajo\Clinica\Medberos\NewMed\consultia\backend\server.py#L283-L302):**

**ANTES (actual):**
```python
# 1) Streaming de asistente
asyncio.create_task(stream_summary(ws, state["final"]))

# 2) Form extraction
asyncio.create_task(run_incremental_update(...))
```

**DESPU√âS (mejorado):**
```python
# 1) Primero extraer formulario y calcular missing/suggestions
await run_incremental_update_sync(...)  # Versi√≥n s√≠ncrona

# 2) Luego generar resumen con contexto completo
missing = state.get("missing", [])
suggestions = state.get("suggestions", [])
asyncio.create_task(stream_summary(ws, state["final"], missing, suggestions))
```

**Ventaja:**
- El asistente IA tiene acceso a la informaci√≥n m√°s actualizada
- Puede guiar al m√©dico sobre qu√© falta

**Desventaja:**
- El resumen tarda un poco m√°s en aparecer (debe esperar extracci√≥n de formulario)

---

### Opci√≥n 3: Sistema de 2 fases (Resumen r√°pido + An√°lisis detallado)

**Fase 1: Resumen inmediato (actual)**
```
"Paciente con fiebre y s√≠ntomas respiratorios."
```

**Fase 2: An√°lisis despu√©s de form_update**
```
"An√°lisis de completitud: ‚úÖ S√≠ntomas registrados.
‚ö†Ô∏è Pendiente: diagn√≥sticos y tratamientos."
```

**Implementaci√≥n:**
- Mantener `stream_summary()` como est√° (r√°pido)
- Agregar una nueva funci√≥n `stream_completeness_check()` que se llame al final de `run_incremental_update()`

---

## üìä COMPARACI√ìN DE OPCIONES

| Opci√≥n | Velocidad | Precisi√≥n | Complejidad |
|--------|-----------|-----------|-------------|
| **Opci√≥n 1** | ‚ö° R√°pida | ‚≠ê‚≠ê‚≠ê Alta | üîß Media |
| **Opci√≥n 2** | üê¢ Lenta | ‚≠ê‚≠ê‚≠ê‚≠ê Muy Alta | üîß Media |
| **Opci√≥n 3** | ‚ö°‚ö° Muy r√°pida | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Excelente | üîßüîß Alta |

**Recomendaci√≥n:** **Opci√≥n 3** (sistema de 2 fases) para mejor UX.

---

## üéØ IMPLEMENTACI√ìN RECOMENDADA

### Modificaci√≥n m√≠nima (Opci√≥n 1 simplificada)

**Archivo:** `consultia/backend/server.py`

**Cambio en l√≠nea 100:**
```python
async def stream_summary(ws: WebSocket, transcript: str, current_form: dict = {}):
    # Calcular campos faltantes in-situ
    missing = compute_missing(current_form)

    # Construir prompt contextualizado
    system = (
        "Eres un asistente cl√≠nico. Resume en 2‚Äì4 l√≠neas lo m√°s relevante del caso: "
        "motivo de consulta, s√≠ntomas clave, hallazgos. "
        "Si identificas informaci√≥n faltante importante, menci√≥nala brevemente. "
        "Mant√©n tono profesional."
    )

    user_prompt = transcript
    if missing:
        missing_friendly = []
        map_friendly = {
            "afiliacion.motivoConsulta": "motivo de consulta",
            "anamnesis.sintomasPrincipales": "s√≠ntomas principales",
            "diagnosticos": "diagn√≥sticos",
            "tratamientos": "plan de tratamiento"
        }
        for m in missing:
            missing_friendly.append(map_friendly.get(m, m))

        user_prompt += f"\n\n[NOTA: Campos pendientes de registro: {', '.join(missing_friendly)}]"

    stream = client.chat.completions.create(
        model=OPENAI_MODEL_TEXT,
        messages=[
            {"role": "system", "content": system},
            {"role": "user", "content": user_prompt}
        ],
        temperature=0.2,
        stream=True
    )
    # ... resto del c√≥digo igual
```

**Cambio en l√≠nea 285:**
```python
asyncio.create_task(stream_summary(ws, state["final"], state.get("json_state", {})))
```

**Resultado esperado:**
```
Asistente IA: "Paciente con cuadro febril y sintomatolog√≠a respiratoria.
Se registraron s√≠ntomas principales. Pendiente de completar: diagn√≥sticos
y plan de tratamiento."
```

---

## ‚úÖ RESUMEN FINAL

### Estado actual:
- ‚úÖ El asistente IA lee todo el transcript
- ‚ùå NO lee campos faltantes
- ‚ùå NO lee sugerencias
- ‚ùå NO puede guiar al m√©dico activamente

### Con la mejora propuesta:
- ‚úÖ El asistente IA lee todo el transcript
- ‚úÖ Lee campos faltantes
- ‚úÖ Puede mencionar qu√© falta
- ‚úÖ Gu√≠a activamente al m√©dico

---

¬øQuieres que implemente alguna de estas opciones?
